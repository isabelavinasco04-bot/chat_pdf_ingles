# Interfaz de pregunta
st.subheader("Escribe quÃ© quieres saber sobre el documento")
user_question = st.text_area(" ", placeholder="Escribe tu pregunta aquÃ­...")

# Selector de idioma de respuesta
response_lang = st.selectbox("Idioma de respuesta", ["InglÃ©s ğŸ‡¬ğŸ‡§", "Italiano ğŸ‡®ğŸ‡¹"], index=0)
lang_instruction = "Please answer in English." if response_lang == "InglÃ©s ğŸ‡¬ğŸ‡§" else "Rispondi in italiano."

# Procesar pregunta
if user_question:
    docs = knowledge_base.similarity_search(user_question)
    
    # Modelo de lenguaje
    llm = OpenAI(temperature=0, model_name="gpt-4o")

    # Cargar cadena de QA
    chain = load_qa_chain(llm, chain_type="stuff")
    
    # Agregar instrucciÃ³n de idioma
    full_question = f"{user_question}\n\n{lang_instruction}"

    # Ejecutar el chain
    response = chain.run(input_documents=docs, question=full_question)

    # Mostrar resultado
    st.markdown("### Respuesta:")
    st.markdown(response)
ğŸŒ Â¿QuÃ© hace esto?
Muestra un menÃº con las opciones â€œInglÃ©s ğŸ‡¬ğŸ‡§â€ o â€œItaliano ğŸ‡®ğŸ‡¹â€

SegÃºn la opciÃ³n, el prompt agrega automÃ¡ticamente:

"Please answer in English." o

"Rispondi in italiano."

El modelo (GPT-4o) responderÃ¡ en ese idioma, sin importar el idioma del PDF o de la pregunta.

Â¿Quieres que ademÃ¡s te lo deje con banderitas en los botones o color rosado en el selector para mantener la estÃ©tica de tus otras apps? ğŸ€







TÃº dijiste:
pero dame todo el codigo


ChatGPT Plus
Perfecto Isa ğŸ’–âœ¨ aquÃ­ tienes todo tu cÃ³digo completo, ya actualizado para que:

La interfaz siga en espaÃ±ol,

Pero el modelo responda en inglÃ©s o en italiano, segÃºn lo que elijas en el menÃº,

Todo perfectamente integrado y con tu estructura original intacta.

ğŸ§ Chat PDF Multilenguaje (EspaÃ±ol UI, inglÃ©s/italiano output)
python
Copiar cÃ³digo
import os
import streamlit as st
from PIL import Image
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
import platform

# ---------- ConfiguraciÃ³n de la App ----------
st.set_page_config(page_title="RAG Multilenguaje ğŸ’¬", page_icon="ğŸ“š", layout="centered")

# TÃ­tulo e info general
st.title('GeneraciÃ³n Aumentada por RecuperaciÃ³n (RAG) ğŸ’¬')
st.write("VersiÃ³n de Python:", platform.python_version())

# Imagen decorativa
try:
    image = Image.open('Chat_pdf.png')
    st.image(image, width=350)
except Exception as e:
    st.warning(f"No se pudo cargar la imagen: {e}")

# Sidebar informativa
with st.sidebar:
    st.subheader("Asistente de anÃ¡lisis de PDF")
    st.write("Este agente te ayudarÃ¡ a realizar anÃ¡lisis sobre el PDF cargado.")
    st.caption("ğŸ’¡ Ahora puedes elegir que las respuestas sean en inglÃ©s o italiano.")

# Clave API
ke = st.text_input('Ingresa tu Clave de OpenAI', type="password")
if ke:
    os.environ['OPENAI_API_KEY'] = ke
else:
    st.warning("Por favor ingresa tu clave de API de OpenAI para continuar")

# Carga del PDF
pdf = st.file_uploader("Carga el archivo PDF", type="pdf")

# Procesamiento del PDF
if pdf is not None and ke:
    try:
        # Extraer texto del PDF
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        
        st.info(f"Texto extraÃ­do: {len(text)} caracteres")
        
        # Dividir texto en fragmentos
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=500,
            chunk_overlap=20,
            length_function=len
        )
        chunks = text_splitter.split_text(text)
        st.success(f"Documento dividido en {len(chunks)} fragmentos")
        
        # Crear embeddings y base de conocimiento
        embeddings = OpenAIEmbeddings()
        knowledge_base = FAISS.from_texts(chunks, embeddings)
        
        # SecciÃ³n de pregunta
        st.subheader("Escribe quÃ© quieres saber sobre el documento")
        user_question = st.text_area(" ", placeholder="Escribe tu pregunta aquÃ­...")

        # SelecciÃ³n de idioma de respuesta
        response_lang = st.selectbox("Idioma de respuesta", ["InglÃ©s ğŸ‡¬ğŸ‡§", "Italiano ğŸ‡®ğŸ‡¹"], index=0)
        lang_instruction = "Please answer in English." if response_lang == "InglÃ©s ğŸ‡¬ğŸ‡§" else "Rispondi in italiano."

        # Procesar pregunta
        if user_question:
            docs = knowledge_base.similarity_search(user_question)
            
            # Crear modelo (GPT-4o o compatible)
            llm = OpenAI(temperature=0, model_name="gpt-4o")

            # Cargar cadena QA
            chain = load_qa_chain(llm, chain_type="stuff")
            
            # Agregar instrucciÃ³n de idioma al prompt
            full_question = f"{user_question}\n\n{lang_instruction}"

            with st.spinner("Analizando el documento... âœ¨"):
                response = chain.run(input_documents=docs, question=full_question)

            # Mostrar respuesta
            st.markdown("### Respuesta:")
            st.markdown(response)
                
    except Exception as e:
        st.error(f"Error al procesar el PDF: {str(e)}")
        import traceback
        st.error(traceback.format_exc())

elif pdf is not None and not ke:
    st.warning("Por favor ingresa tu clave de API de OpenAI para continuar")
else:
    st.info("Por favor carga un archivo PDF para comenzar")
