import os
import streamlit as st
from PIL import Image
from PyPDF2 import PdfReader
from langchain.text_splitter import CharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from langchain.vectorstores import FAISS
from langchain.llms import OpenAI
from langchain.chains.question_answering import load_qa_chain
import platform

# ---------- ConfiguraciÃ³n de la App ----------
st.set_page_config(page_title="RAG Multilenguaje directioner ðŸ’¬", page_icon="ðŸ“š", layout="centered")

# TÃ­tulo e info general
st.title('RAG directioner multilingue ðŸ’¬')
st.write("VersiÃ³n de Python:", platform.python_version())

# Imagen decorativa
try:
    image = Image.open('Chat_pdf.png')
    st.image(image, width=350)
except Exception as e:
    st.warning(f"No se pudo cargar la imagen: {e}")

# Sidebar informativa
with st.sidebar:
    st.subheader("Asistente de anÃ¡lisis de PDF")
    st.write("Este agente te ayudarÃ¡ a realizar anÃ¡lisis sobre el PDF cargado.")
    st.caption("ðŸ’¡ Ahora puedes elegir que las respuestas sean en inglÃ©s o italiano.")

# Clave API
ke = st.text_input('Ingresa tu Clave de OpenAI', type="password")
if ke:
    os.environ['OPENAI_API_KEY'] = ke
else:
    st.warning("Por favor ingresa tu clave de API de OpenAI para continuar")

# Carga del PDF
pdf = st.file_uploader("Carga el archivo PDF", type="pdf")

# Procesamiento del PDF
if pdf is not None and ke:
    try:
        # Extraer texto del PDF
        pdf_reader = PdfReader(pdf)
        text = ""
        for page in pdf_reader.pages:
            text += page.extract_text()
        
        st.info(f"Texto extraÃ­do: {len(text)} caracteres")
        
        # Dividir texto en fragmentos
        text_splitter = CharacterTextSplitter(
            separator="\n",
            chunk_size=500,
            chunk_overlap=20,
            length_function=len
        )
        chunks = text_splitter.split_text(text)
        st.success(f"Documento dividido en {len(chunks)} fragmentos")
        
        # Crear embeddings y base de conocimiento
        embeddings = OpenAIEmbeddings()
        knowledge_base = FAISS.from_texts(chunks, embeddings)
        
        # SecciÃ³n de pregunta
        st.subheader("Escribe quÃ© quieres saber sobre el documento")
        user_question = st.text_area(" ", placeholder="Escribe tu pregunta aquÃ­...")

        # SelecciÃ³n de idioma de respuesta
        response_lang = st.selectbox("Idioma de respuesta", ["InglÃ©s ðŸ‡¬ðŸ‡§", "Italiano ðŸ‡®ðŸ‡¹"], index=0)
        lang_instruction = "Please answer in English." if response_lang == "InglÃ©s ðŸ‡¬ðŸ‡§" else "Rispondi in italiano."

        # Procesar pregunta
        if user_question:
            docs = knowledge_base.similarity_search(user_question)
            
            # Crear modelo (GPT-4o o compatible)
            llm = OpenAI(temperature=0, model_name="gpt-4o")

            # Cargar cadena QA
            chain = load_qa_chain(llm, chain_type="stuff")
            
            # Agregar instrucciÃ³n de idioma al prompt
            full_question = f"{user_question}\n\n{lang_instruction}"

            with st.spinner("Analizando el documento... âœ¨"):
                response = chain.run(input_documents=docs, question=full_question)

            # Mostrar respuesta
            st.markdown("### Respuesta:")
            st.markdown(response)
                
    except Exception as e:
        st.error(f"Error al procesar el PDF: {str(e)}")
        import traceback
        st.error(traceback.format_exc())

elif pdf is not None and not ke:
    st.warning("Por favor ingresa tu clave de API de OpenAI para continuar")
else:
    st.info("Por favor carga un archivo PDF para comenzar")
